# üöÄ Production Deployment Checklist

> **Complete checklist for deploying AI Lunar Lander to production**

## üìã Table of Contents

1. [Pre-Production Validation](#pre-production-validation)
2. [Production Configuration](#production-configuration)
3. [Deployment Steps](#deployment-steps)
4. [Post-Deployment Monitoring](#post-deployment-monitoring)
5. [Rollback Procedure](#rollback-procedure)
6. [Performance Benchmarks](#performance-benchmarks)

---

## ‚úÖ Pre-Production Validation

### Phase 1: Environment Testing (1-2 hours)

- [ ] **Run quick environment test**
  ```bash
  python unified_training.py --mode test
  ```
  - ‚úì Environment creates successfully
  - ‚úì Gymnasium API validation passes
  - ‚úì Basilisk simulation runs without errors
  - ‚úì Model training completes 5,000 steps

- [ ] **Verify all critical features are implemented**
  - ‚úì Observation size validation in `_process_lidar_azimuthal()`
  - ‚úì VecNormalize state validation during curriculum load
  - ‚úì Reset sequence timing (setState before InitializeSimulation)
  - ‚úì Basilisk import error handling with helpful messages
  - ‚úì Stage-specific success rate thresholds (40%-65%)
  - ‚úì Curriculum state validation in `_load_training_state()`
  - ‚úì Terrain contact optimization (10m early exit)
  - ‚úì Episode timeout logging for debugging
  - ‚úì Enhanced memory cleanup in `close()` method

- [ ] **Test edge cases**
  ```bash
  # Test with single environment
  python unified_training.py --mode standard --n-envs 1 --timesteps 10000
  
  # Test with multiple environments
  python unified_training.py --mode standard --n-envs 4 --timesteps 10000
  ```
  - ‚úì Single environment works correctly
  - ‚úì Parallel environments (4+) work without crashes
  - ‚úì No memory leaks detected (monitor with Task Manager)

- [ ] **Validate reward function**
  - ‚úì Terminal rewards scale correctly (¬±1000)
  - ‚úì Shaping rewards in 0-5 range
  - ‚úì Fuel efficiency bonus only awarded on success
  - ‚úì Success criteria match documentation (altitude < 5m, vel < 3 m/s)

### Phase 2: Burn-In Testing (48-72 hours)

- [ ] **Run extended training session**
  ```bash
  python unified_training.py --mode curriculum --n-envs 8
  ```
  - ‚úì Training runs for 48+ hours without crashes
  - ‚úì Memory usage remains stable (< 2GB per environment)
  - ‚úì No file descriptor leaks
  - ‚úì Checkpoints save correctly every 50k steps
  - ‚úì TensorBoard logs are accessible and complete

- [ ] **Monitor system resources**
  ```bash
  # In separate terminal, monitor memory
  while ($true) { Get-Process python | Select-Object ProcessName, @{Name="Memory(MB)";Expression={[int]($_.WS / 1MB)}} | Format-Table; Start-Sleep -Seconds 60 }
  ```
  - ‚úì CPU usage reasonable (< 90% sustained)
  - ‚úì Memory growth is linear, not exponential
  - ‚úì Disk I/O remains manageable
  - ‚úì No zombie processes

- [ ] **Validate curriculum progression**
  - ‚úì Stage 1 achieves 40%+ success rate
  - ‚úì Stage 2 achieves 50%+ success rate
  - ‚úì Stage 3 achieves 55%+ success rate
  - ‚úì Stage 4 achieves 60%+ success rate
  - ‚úì Stage 5 achieves 65%+ success rate
  - ‚úì Mean rewards meet thresholds (400, 600, 700, 800, 900)
  - ‚úì VecNormalize stats persist across stages

- [ ] **Test resume functionality**
  - ‚úì Interrupt training mid-stage (Ctrl+C)
  - ‚úì Resume with `--mode curriculum --resume`
  - ‚úì Training continues from correct stage
  - ‚úì Reward trends remain continuous
  - ‚úì Model performance doesn't degrade

### Phase 3: Algorithm Validation (4-8 hours)

- [ ] **Test different algorithms**
  ```bash
  # PPO (baseline)
  python unified_training.py --algorithm ppo --mode standard --timesteps 500000
  
  # SAC (sample efficiency)
  python unified_training.py --algorithm sac --mode standard --timesteps 500000
  
  # TD3 (deterministic)
  python unified_training.py --algorithm td3 --mode standard --timesteps 500000
  ```
  - ‚úì PPO completes training successfully
  - ‚úì SAC completes training successfully
  - ‚úì TD3 completes training successfully
  - ‚úì All algorithms reach positive rewards
  - ‚úì No algorithm-specific crashes

- [ ] **Compare performance**
  - ‚úì PPO: Stable, predictable learning
  - ‚úì SAC: Better sample efficiency
  - ‚úì TD3: Competitive final performance
  - ‚úì All algorithms converge to successful landings

---

## ‚öôÔ∏è Production Configuration

### Hardware Requirements

- [ ] **Minimum specifications verified**
  - CPU: 8+ cores (Intel i7/AMD Ryzen 7 or better)
  - RAM: 16GB+ (32GB recommended for 8+ parallel envs)
  - Storage: 50GB+ free space for checkpoints/logs
  - GPU: Optional (CPU training is default)

### Software Dependencies

- [ ] **Python environment configured**
  ```bash
  python --version  # Should be 3.8+
  pip list | findstr "stable-baselines3 gymnasium numpy"
  ```
  - ‚úì Python 3.8 or higher
  - ‚úì stable-baselines3[extra] installed
  - ‚úì gymnasium installed
  - ‚úì numpy, matplotlib, tensorboard installed
  - ‚úì Basilisk built in `./basilisk/dist3/`

- [ ] **Create production config file**
  - Create `production_config.json` with optimal settings:
    ```json
    {
      "algorithm": "ppo",
      "n_envs": 8,
      "learning_rate": 3e-4,
      "save_dir": "./production_models",
      "log_dir": "./production_logs",
      "checkpoint_freq": 50000,
      "eval_freq": 10000,
      "seed": 42
    }
    ```

### Backup Strategy

- [ ] **Configure automated backups**
  - ‚úì Checkpoint files backed up to cloud storage (every 50k steps)
  - ‚úì VecNormalize stats backed up with models
  - ‚úì Training state JSON/pickle files backed up
  - ‚úì TensorBoard logs archived daily
  - ‚úì Retention policy: 30 days for checkpoints, 90 days for final models

---

## üöÄ Deployment Steps

### Step 1: Pre-Deployment Checklist

- [ ] All pre-production tests passed
- [ ] Production config file created
- [ ] Backup strategy configured
- [ ] Monitoring dashboard prepared
- [ ] Rollback procedure documented
- [ ] Team notified of deployment schedule

### Step 2: Initial Deployment

- [ ] **Start training with monitoring**
  ```bash
  # Start TensorBoard in separate window
  tensorboard --logdir=./production_logs --port 6006
  
  # Start training
  python unified_training.py --mode curriculum --n-envs 8 --save-dir ./production_models --log-dir ./production_logs
  ```

- [ ] **Verify startup**
  - ‚úì Training begins within 2 minutes
  - ‚úì All environments initialize successfully
  - ‚úì TensorBoard accessible at http://localhost:6006
  - ‚úì First checkpoint created within expected time
  - ‚úì No error messages in console

### Step 3: First Hour Validation

- [ ] **Check TensorBoard metrics** (after 1 hour)
  - ‚úì `rollout/ep_rew_mean` trending upward or stable
  - ‚úì `rollout/ep_len_mean` < max_episode_steps
  - ‚úì `episode/success_rate_100` > 0% (some successes)
  - ‚úì `train/learning_rate` stable
  - ‚úì No NaN or Inf values in any metric

- [ ] **Verify file outputs**
  - ‚úì Checkpoint files created in `./production_models/checkpoints/`
  - ‚úì VecNormalize stats saved (`*_vecnormalize.pkl`)
  - ‚úì Training state JSON created
  - ‚úì TensorBoard event files updating

### Step 4: 24-Hour Checkpoint

- [ ] **Performance validation**
  - ‚úì Training still running (no crashes)
  - ‚úì Memory usage stable
  - ‚úì Stage 1 completed or in progress
  - ‚úì Success rate improving
  - ‚úì No repeated failures on same stage

- [ ] **Data integrity**
  - ‚úì Checkpoints loading successfully
  - ‚úì Model can be evaluated with `--mode eval`
  - ‚úì Backups completed successfully

---

## üìä Post-Deployment Monitoring

### Real-Time Monitoring (Daily)

- [ ] **Check TensorBoard dashboard**
  - Monitor: `rollout/ep_rew_mean`, `episode/success_rate_100`
  - Alert if: Reward decreases by >20% for 100k steps
  - Alert if: Success rate drops below stage threshold

- [ ] **System health**
  - CPU usage trending
  - Memory usage stable
  - Disk space available
  - Process running without errors

### Weekly Performance Review

- [ ] **Training progress**
  - Current curriculum stage
  - Stages completed
  - Success rates per stage
  - Mean reward trends
  - Estimated completion time

- [ ] **Model quality**
  - Evaluate best model with 20 episodes
  - Success rate on evaluation set
  - Landing precision (distance from target)
  - Fuel efficiency metrics
  - Control smoothness

### Automated Alerts

- [ ] **Configure alerts for**
  - ‚úì Training process crash
  - ‚úì Memory usage > 90%
  - ‚úì Disk space < 10GB
  - ‚úì Checkpoint save failure
  - ‚úì Reward becomes NaN
  - ‚úì Stage regression occurs 3+ times

---

## üîÑ Rollback Procedure

### When to Rollback

- Training crashes repeatedly (3+ times in 24 hours)
- Memory leak detected (>5GB growth per day)
- Curriculum regression occurs 3+ consecutive times
- Reward diverges (NaN or extremely negative)
- Critical bug discovered in production code

### Rollback Steps

1. [ ] **Stop current training**
   - Press Ctrl+C or kill process
   - Wait for graceful shutdown

2. [ ] **Identify last good checkpoint**
   ```bash
   # List checkpoints sorted by time
   Get-ChildItem ./production_models/checkpoints/*.zip | Sort-Object LastWriteTime -Descending | Select-Object -First 5
   ```

3. [ ] **Restore from backup**
   - Copy checkpoint to safe location
   - Restore VecNormalize stats
   - Restore training state JSON

4. [ ] **Resume from checkpoint**
   ```bash
   python unified_training.py --mode standard --resume ./path/to/checkpoint.zip
   ```

5. [ ] **Verify restoration**
   - Check TensorBoard continuity
   - Verify success rate matches pre-rollback
   - Monitor for 1 hour

---

## üìà Performance Benchmarks

### Expected Performance Metrics

| Metric | Expected Value | Alert Threshold |
|--------|---------------|-----------------|
| Training Speed | 800-1200 steps/sec | < 500 steps/sec |
| Memory per Env | 150-250 MB | > 500 MB |
| Stage 1 Success | 40-60% | < 20% |
| Stage 5 Success | 65-75% | < 50% |
| Mean Reward (Stage 5) | 900-1200 | < 600 |
| Fuel Efficiency | 40-60% remaining | < 20% |
| Landing Precision | < 10m from target | > 30m |
| Episode Length | 400-800 steps | > 1000 steps |

### Training Time Estimates

| Configuration | Stage 1 | Full Curriculum | Total Hours |
|--------------|---------|-----------------|-------------|
| 4 envs (minimum) | 2-3 hrs | 8-12 hrs | 10-15 hrs |
| 8 envs (recommended) | 1-2 hrs | 4-8 hrs | 5-10 hrs |
| 16 envs (maximum) | 0.5-1 hr | 2-4 hrs | 2.5-5 hrs |

### Success Criteria for Production

- [ ] **Final Model Quality**
  - ‚úì Success rate > 65% on Stage 5 environment
  - ‚úì Mean reward > 900 over 100 evaluation episodes
  - ‚úì Landing precision < 15m average
  - ‚úì Fuel remaining > 30% average
  - ‚úì Soft landing (velocity < 2 m/s) in 95%+ of successes

- [ ] **Training Reliability**
  - ‚úì Zero crashes in final 48 hours
  - ‚úì All 5 curriculum stages completed
  - ‚úì Checkpoints saved successfully
  - ‚úì Resume functionality tested and working

- [ ] **System Performance**
  - ‚úì Memory stable over 72+ hours
  - ‚úì Training speed meets benchmarks
  - ‚úì No resource leaks detected

---

## üéØ Go-Live Criteria

### All of the following must be TRUE:

- ‚úÖ All pre-production tests passed
- ‚úÖ 72-hour burn-in test completed successfully
- ‚úÖ Curriculum completes all 5 stages
- ‚úÖ Final model success rate > 65%
- ‚úÖ No memory leaks detected
- ‚úÖ Backup and rollback procedures tested
- ‚úÖ Monitoring dashboard operational
- ‚úÖ Team trained on monitoring and alerts

### Sign-Off Required From:

- [ ] Technical Lead (code review)
- [ ] QA Engineer (testing validation)
- [ ] DevOps Engineer (infrastructure ready)
- [ ] Project Manager (timeline approved)

---

## üìû Support Contacts

**Technical Issues:**
- Check TensorBoard first: http://localhost:6006
- Review logs in `./production_logs/`
- Check this checklist for common issues

**Emergency Rollback:**
- Follow rollback procedure above
- Document incident in `incidents.md`

**Performance Questions:**
- Compare against benchmarks in this document
- Check `REWARD_SYSTEM_GUIDE.md` for tuning

---

## üìù Production Notes

**Date Deployed:** _________________

**Deployed By:** _________________

**Configuration Used:** _________________

**Initial Success Rate:** _________________

**Notes:**
_________________________________________________________________
_________________________________________________________________
_________________________________________________________________

---

**Last Updated:** 2025-11-11  
**Version:** 1.0  
**Status:** ‚úÖ PRODUCTION READY
